{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandasql import sqldf\n",
    "import pandas_profiling\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Basics\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "#### For Feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from treeinterpreter import treeinterpreter as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, datasets, ensemble\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>prices_availability</th>\n",
       "      <th>prices_condition</th>\n",
       "      <th>prices_isSale</th>\n",
       "      <th>prices_merchant_x</th>\n",
       "      <th>brand_x</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>weight_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "      <th>category_5</th>\n",
       "      <th>category_6</th>\n",
       "      <th>shipping_flag</th>\n",
       "      <th>n_days_since_added</th>\n",
       "      <th>n_days_since_updated</th>\n",
       "      <th>prices_merchant_y</th>\n",
       "      <th>brand_y</th>\n",
       "      <th>price_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AVphzgbJLJeJML43fA0o</td>\n",
       "      <td>In Stock</td>\n",
       "      <td>New</td>\n",
       "      <td>False</td>\n",
       "      <td>Bestbuy.com</td>\n",
       "      <td>Sanus</td>\n",
       "      <td>VLF410B1</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>32.8</td>\n",
       "      <td>...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>A/V Presentation</td>\n",
       "      <td>Accessories &amp; Supplies</td>\n",
       "      <td>TV Ceiling &amp; Wall Mounts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2313</td>\n",
       "      <td>1188</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>104.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    id prices_availability prices_condition  \\\n",
       "0           0  AVphzgbJLJeJML43fA0o            In Stock              New   \n",
       "\n",
       "   prices_isSale prices_merchant_x brand_x manufacturerNumber  \\\n",
       "0          False       Bestbuy.com   Sanus           VLF410B1   \n",
       "\n",
       "  primaryCategories  weight_norm  ...   category_3        category_4  \\\n",
       "0       Electronics         32.8  ...  Electronics  A/V Presentation   \n",
       "\n",
       "               category_5                category_6 shipping_flag  \\\n",
       "0  Accessories & Supplies  TV Ceiling & Wall Mounts           NaN   \n",
       "\n",
       "  n_days_since_added n_days_since_updated prices_merchant_y  brand_y  \\\n",
       "0               2313                 1188                 1        2   \n",
       "\n",
       "   price_USD  \n",
       "0     104.99  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"...data_train_non_trans_merge_final_dup.csv\")\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[['weight_norm',\n",
    "                   'n_days_since_added',\n",
    "                   'category_2',\n",
    "                   'category_4',\n",
    "                   'manufacturerNumber',\n",
    "                   'category_1',\n",
    "                   'category_0',\n",
    "                   'price_USD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight_norm           float64\n",
       "n_days_since_added      int64\n",
       "category_2             object\n",
       "category_4             object\n",
       "manufacturerNumber     object\n",
       "category_1             object\n",
       "category_0             object\n",
       "price_USD             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I347687\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\I347687\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\I347687\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\I347687\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\I347687\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "data_train['manufacturerNumber'] = data_train['manufacturerNumber'].astype(str)\n",
    "data_train['category_4'] = data_train['category_4'].astype(str)\n",
    "data_train['category_2'] = data_train['category_2'].astype(str)\n",
    "data_train['category_1'] = data_train['category_1'].astype(str)\n",
    "data_train['category_0'] = data_train['category_0'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_t_imputed = data_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight_norm           float64\n",
       "n_days_since_added      int64\n",
       "category_2             object\n",
       "category_4             object\n",
       "manufacturerNumber     object\n",
       "category_1             object\n",
       "category_0             object\n",
       "price_USD             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_t_imputed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start with base line model, which is the average price of product of different categories. \n",
    "# In other words, in our base line model, price prediction will be the average price of product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_median = data_train.pivot_table(index=['category_2', 'category_4', 'category_1', 'category_0'], values=['price_USD'], aggfunc=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_baseline_model = pd.merge(category_median, data_train, how='left',\n",
    "                  left_on = ['category_2', 'category_4', 'category_1', 'category_0'], right_on = ['category_2', 'category_4', 'category_1', 'category_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mean Absolute Error of this simplistic approach is 103.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.75712379471254"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(abs(data_train_baseline_model['price_USD_x'] - data_train_baseline_model['price_USD_y'])))/14146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor - top7 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(data_train_t_imputed.select_dtypes(exclude=[\"number\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_norm</th>\n",
       "      <th>n_days_since_added</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_4</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_0</th>\n",
       "      <th>price_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.8</td>\n",
       "      <td>2313</td>\n",
       "      <td>322</td>\n",
       "      <td>23</td>\n",
       "      <td>1120</td>\n",
       "      <td>299</td>\n",
       "      <td>15</td>\n",
       "      <td>104.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1216</td>\n",
       "      <td>322</td>\n",
       "      <td>11</td>\n",
       "      <td>734</td>\n",
       "      <td>299</td>\n",
       "      <td>15</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.0</td>\n",
       "      <td>2113</td>\n",
       "      <td>322</td>\n",
       "      <td>11</td>\n",
       "      <td>1134</td>\n",
       "      <td>299</td>\n",
       "      <td>15</td>\n",
       "      <td>419.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175.0</td>\n",
       "      <td>2113</td>\n",
       "      <td>322</td>\n",
       "      <td>11</td>\n",
       "      <td>1134</td>\n",
       "      <td>299</td>\n",
       "      <td>15</td>\n",
       "      <td>579.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.0</td>\n",
       "      <td>2113</td>\n",
       "      <td>322</td>\n",
       "      <td>11</td>\n",
       "      <td>1134</td>\n",
       "      <td>299</td>\n",
       "      <td>15</td>\n",
       "      <td>398.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_norm  n_days_since_added  category_2  category_4  \\\n",
       "0         32.8                2313         322          23   \n",
       "1         30.0                1216         322          11   \n",
       "2        175.0                2113         322          11   \n",
       "3        175.0                2113         322          11   \n",
       "4        175.0                2113         322          11   \n",
       "\n",
       "   manufacturerNumber  category_1  category_0  price_USD  \n",
       "0                1120         299          15     104.99  \n",
       "1                 734         299          15      99.99  \n",
       "2                1134         299          15     419.95  \n",
       "3                1134         299          15     579.99  \n",
       "4                1134         299          15     398.99  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(categorical_features)):\n",
    "    new = le.fit_transform(data_train_t_imputed[categorical_features[i]])\n",
    "    data_train_t_imputed[categorical_features[i]] = new\n",
    "data_train_t_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some records apart to test our model further on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The independent features set: \n",
      "[[  32.8 2313.   322.    23.  1120.   299.    15. ]\n",
      " [  30.  1216.   322.    11.   734.   299.    15. ]\n",
      " [ 175.  2113.   322.    11.  1134.   299.    15. ]\n",
      " [ 175.  2113.   322.    11.  1134.   299.    15. ]\n",
      " [ 175.  2113.   322.    11.  1134.   299.    15. ]]\n",
      "The dependent variable: \n",
      "[104.99  99.99 419.95 579.99 398.99]\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X = data_train_t_imputed.iloc[:,0:7].values\n",
    "y = data_train_t_imputed.iloc[:,7].values\n",
    "print('The independent features set: ')\n",
    "print(X[:5,:])\n",
    "print('The dependent variable: ')\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use Random Search to find the best parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 30, num = 7)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(start = 5, stop = 20, num = 7)]\n",
    "min_samples_split = [5, 10, 20]\n",
    "min_samples_leaf = [1, 3, 4, 5]\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [5, 7, 10, 12, 15, 17, 20],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 3, 4, 5],\n",
      " 'min_samples_split': [5, 10, 20],\n",
      " 'n_estimators': [5, 9, 13, 17, 21, 25, 30]}\n"
     ]
    }
   ],
   "source": [
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 400, cv = 10, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3285 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=400, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [5, 7, 10, 12, 15, 17, 20],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 3, 4, 5],\n",
       "                                        'min_samples_split': [5, 10, 20],\n",
       "                                        'n_estimators': [5, 9, 13, 17, 21, 25,\n",
       "                                                         30]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 17,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119136</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896612</td>\n",
       "      <td>0.930759</td>\n",
       "      <td>0.909144</td>\n",
       "      <td>0.837386</td>\n",
       "      <td>0.55412</td>\n",
       "      <td>0.889059</td>\n",
       "      <td>0.827046</td>\n",
       "      <td>0.863612</td>\n",
       "      <td>0.109585</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.119136      0.009312         0.003889        0.000536   \n",
       "\n",
       "  param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                  5                      10                      3   \n",
       "\n",
       "  param_max_features param_max_depth param_bootstrap  ... split3_test_score  \\\n",
       "0               sqrt              15           False  ...          0.896612   \n",
       "\n",
       "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0           0.930759           0.909144           0.837386            0.55412   \n",
       "\n",
       "   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.889059           0.827046         0.863612        0.109585   \n",
       "\n",
       "   rank_test_score  \n",
       "0               41  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_random.cv_results_).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_results = pd.DataFrame(rf_random.cv_results_)[['params','rank_test_score','mean_test_score']].sort_values(by=[\"rank_test_score\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_iter = 10\n",
    "rf_importance = pd.DataFrame(columns = ['Feature', 'Importance_rf', 'Iteration_n'])\n",
    "importance = []\n",
    "\n",
    "for i in range(num_iter):\n",
    "\n",
    "    rf = RandomForestRegressor(bootstrap = True, n_estimators = 21, max_features='sqrt',  min_samples_leaf = 1, min_samples_split = 5, max_depth = 20, criterion = 'mse')\n",
    "    rf.fit(X_train, y_train)\n",
    "    importance = pd.DataFrame(list(zip(data_train_t_imputed.columns[0:X_train.shape[1]], rf.feature_importances_)))\n",
    "    importance.rename(columns = {importance.columns[0] : 'Feature', importance.columns[1] : 'Importance_rf'}, inplace = True)\n",
    "    importance['Iteration_n'] = i\n",
    "    rf_importance = rf_importance.append(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weight_norm</td>\n",
       "      <td>0.370945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category_2</td>\n",
       "      <td>0.136776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_days_since_added</td>\n",
       "      <td>0.118057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manufacturerNumber</td>\n",
       "      <td>0.111414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_4</td>\n",
       "      <td>0.094944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category_0</td>\n",
       "      <td>0.091094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category_1</td>\n",
       "      <td>0.076770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Importance_rf\n",
       "6         weight_norm       0.370945\n",
       "2          category_2       0.136776\n",
       "5  n_days_since_added       0.118057\n",
       "4  manufacturerNumber       0.111414\n",
       "3          category_4       0.094944\n",
       "0          category_0       0.091094\n",
       "1          category_1       0.076770"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_importance_agg = rf_importance.groupby(['Feature'], as_index = False).mean()\n",
    "rf_importance_agg.sort_values('Importance_rf', inplace=True, ascending=False)\n",
    "rf_importance_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 69.52893896, 318.57391017, 441.75922687, ..., 478.45570522,\n",
       "       184.49894322,  80.86814653])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS we can see, the Mean Absolute Error in Random Forest approach is ~101 (slightly better than base line model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 95.27513275168799\n",
      "Mean Squared Error (MSE): 99176.71946003742\n",
      "Root Mean Squared Error (RMSE): 314.92335489772336\n",
      "Explained Variance Score: 0.859872891981674\n",
      "Max Error: 8611.852044716152\n",
      "Mean Squared Log Error: 0.19954300313482756\n",
      "Median Absolute Error: 27.26378831796223\n",
      "R^2: 0.8597355320981503\n",
      "Mean Poisson Deviance: 69.2599189815745\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error (RMSE):', metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "print('Max Error:', metrics.max_error(y_test, y_pred))\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred))\n",
    "print('Mean Poisson Deviance:', metrics.mean_poisson_deviance(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Griadient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use Random Search to find the best parameters for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 30, num = 7)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(start = 5, stop = 20, num = 7)]\n",
    "min_samples_split = [5, 10, 20]\n",
    "min_samples_leaf = [2, 3, 4, 5]\n",
    "#bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [5, 7, 10, 12, 15, 17, 20],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [2, 3, 4, 5],\n",
      " 'min_samples_split': [5, 10, 20],\n",
      " 'n_estimators': [5, 9, 13, 17, 21, 25, 30]}\n"
     ]
    }
   ],
   "source": [
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb_random = RandomizedSearchCV(estimator = gb, param_distributions = random_grid, n_iter = 400, cv = 10, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1037 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1482 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2009 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3305 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(random_state=42),\n",
       "                   n_iter=400, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [5, 7, 10, 12, 15, 17, 20],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [2, 3, 4, 5],\n",
       "                                        'min_samples_split': [5, 10, 20],\n",
       "                                        'n_estimators': [5, 9, 13, 17, 21, 25,\n",
       "                                                         30]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "gb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 30,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 17}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>{'n_estimators': 30, 'min_samples_split': 10, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'n_estimators': 30, 'min_samples_split': 5, '...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>{'n_estimators': 30, 'min_samples_split': 10, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>{'n_estimators': 25, 'min_samples_split': 5, '...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.874362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'n_estimators': 30, 'min_samples_split': 10, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.873743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  rank_test_score  \\\n",
       "118  {'n_estimators': 30, 'min_samples_split': 10, ...                1   \n",
       "6    {'n_estimators': 30, 'min_samples_split': 5, '...                2   \n",
       "116  {'n_estimators': 30, 'min_samples_split': 10, ...                3   \n",
       "306  {'n_estimators': 25, 'min_samples_split': 5, '...                4   \n",
       "31   {'n_estimators': 30, 'min_samples_split': 10, ...                5   \n",
       "\n",
       "     mean_test_score  \n",
       "118         0.875762  \n",
       "6           0.875199  \n",
       "116         0.875061  \n",
       "306         0.874362  \n",
       "31          0.873743  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gb_random.cv_results_)[['params','rank_test_score','mean_test_score']].sort_values(by=[\"rank_test_score\"], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_iter = 10\n",
    "gb_importance = pd.DataFrame(columns = ['Feature', 'Importance_rf', 'Iteration_n'])\n",
    "importance = []\n",
    "\n",
    "for i in range(num_iter):\n",
    "\n",
    "    gb = GradientBoostingRegressor(n_estimators=30, max_features='sqrt', min_samples_leaf = 2, min_samples_split = 10, max_depth=17, learning_rate=0.5, criterion='mse')\n",
    "    gb.fit(X_train, y_train)\n",
    "    importance = pd.DataFrame(list(zip(data_train_t_imputed.columns[0:X_train.shape[1]], gb.feature_importances_)))\n",
    "    importance.rename(columns = {importance.columns[0] : 'Feature', importance.columns[1] : 'Importance_gb'}, inplace = True)\n",
    "    importance['Iteration_n'] = i\n",
    "    gb_importance = gb_importance.append(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weight_norm</td>\n",
       "      <td>0.360774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_days_since_added</td>\n",
       "      <td>0.132823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category_2</td>\n",
       "      <td>0.130579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_4</td>\n",
       "      <td>0.115747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manufacturerNumber</td>\n",
       "      <td>0.113476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category_0</td>\n",
       "      <td>0.085618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category_1</td>\n",
       "      <td>0.060983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Importance_gb\n",
       "6         weight_norm       0.360774\n",
       "5  n_days_since_added       0.132823\n",
       "2          category_2       0.130579\n",
       "3          category_4       0.115747\n",
       "4  manufacturerNumber       0.113476\n",
       "0          category_0       0.085618\n",
       "1          category_1       0.060983"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_importance_agg = gb_importance.groupby(['Feature'], as_index = False).mean()\n",
    "gb_importance_agg.sort_values('Importance_gb', inplace=True, ascending=False)\n",
    "gb_importance_agg.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.32463906, 323.00710211, 438.40211451, ..., 501.37650713,\n",
       "       197.06359003,  83.25490099])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gb.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, the Mean Absolute Error of Gradient Boosting approach is ~97. Also slightly better than baseline and random forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 91.78964817939608\n",
      "Mean Squared Error (MSE): 100231.05777436102\n",
      "Explained Variance Score: 0.8584029212944294\n",
      "Max Error: 8798.140304045164\n",
      "Median Absolute Error: 23.3722172771448\n",
      "R^2: 0.8582443938204145\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
    "#print('Root Mean Squared Error (RMSE):', metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "print('Max Error:', metrics.max_error(y_test, y_pred))\n",
    "#print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred))\n",
    "#print('Mean Poisson Deviance:', metrics.mean_poisson_deviance(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute the combined importance of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_importance = pd.merge(rf_importance_agg,gb_importance_agg, how = 'left', on='Feature')\n",
    "Combined_importance['Avg_Importance'] = (Combined_importance['Importance_rf'] + Combined_importance['Importance_gb'])/2\n",
    "Combined_importance.sort_values('Avg_Importance', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance_rf</th>\n",
       "      <th>Importance_gb</th>\n",
       "      <th>Avg_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weight_norm</td>\n",
       "      <td>0.370945</td>\n",
       "      <td>0.360774</td>\n",
       "      <td>0.365860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category_2</td>\n",
       "      <td>0.136776</td>\n",
       "      <td>0.130579</td>\n",
       "      <td>0.133677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_days_since_added</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>0.132823</td>\n",
       "      <td>0.125440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manufacturerNumber</td>\n",
       "      <td>0.111414</td>\n",
       "      <td>0.113476</td>\n",
       "      <td>0.112445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category_4</td>\n",
       "      <td>0.094944</td>\n",
       "      <td>0.115747</td>\n",
       "      <td>0.105345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>category_0</td>\n",
       "      <td>0.091094</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>0.088356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>category_1</td>\n",
       "      <td>0.076770</td>\n",
       "      <td>0.060983</td>\n",
       "      <td>0.068876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Importance_rf  Importance_gb  Avg_Importance\n",
       "0         weight_norm       0.370945       0.360774        0.365860\n",
       "1          category_2       0.136776       0.130579        0.133677\n",
       "2  n_days_since_added       0.118057       0.132823        0.125440\n",
       "3  manufacturerNumber       0.111414       0.113476        0.112445\n",
       "4          category_4       0.094944       0.115747        0.105345\n",
       "5          category_0       0.091094       0.085618        0.088356\n",
       "6          category_1       0.076770       0.060983        0.068876"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combined_importance.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_norm</th>\n",
       "      <th>n_days_since_added</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_4</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_0</th>\n",
       "      <th>price_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12420</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1623</td>\n",
       "      <td>112</td>\n",
       "      <td>135</td>\n",
       "      <td>685</td>\n",
       "      <td>200</td>\n",
       "      <td>195</td>\n",
       "      <td>1682.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_norm  n_days_since_added  category_2  category_4  \\\n",
       "12420          3.0                1623         112         135   \n",
       "\n",
       "       manufacturerNumber  category_1  category_0  price_USD  \n",
       "12420                 685         200         195    1682.99  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set_sample = testing_set.sample(1)\n",
    "testing_set_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_norm</th>\n",
       "      <th>n_days_since_added</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_4</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_0</th>\n",
       "      <th>price_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12593</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1486</td>\n",
       "      <td>Solid State Drives</td>\n",
       "      <td>Storage &amp; Blank Media</td>\n",
       "      <td>MZ-N5E500BW</td>\n",
       "      <td>Internal Drives</td>\n",
       "      <td>Computers</td>\n",
       "      <td>168.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_norm  n_days_since_added          category_2  \\\n",
       "12593         0.18                1486  Solid State Drives   \n",
       "\n",
       "                   category_4 manufacturerNumber       category_1 category_0  \\\n",
       "12593   Storage & Blank Media        MZ-N5E500BW  Internal Drives  Computers   \n",
       "\n",
       "       price_USD  \n",
       "12593     168.99  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.iloc[[12593]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_norm_value = testing_set_sample.iloc[0]['weight_norm']\n",
    "n_days_since_added_value = testing_set_sample.iloc[0]['n_days_since_added']\n",
    "category_2_value = testing_set_sample.iloc[0]['category_2']\n",
    "category_4_value = testing_set_sample.iloc[0]['category_4']\n",
    "manufacturerNumber_value = testing_set_sample.iloc[0]['manufacturerNumber']\n",
    "category_1_value = testing_set_sample.iloc[0]['category_1']\n",
    "category_0_value = testing_set_sample.iloc[0]['category_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = np.array([[weight_norm_value, n_days_since_added_value,category_2_value,category_4_value, manufacturerNumber_value, category_1_value, category_0_value]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3., 1623.,  112.,  135.,  685.,  200.,  195.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1727.20574239])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(instance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "xai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
